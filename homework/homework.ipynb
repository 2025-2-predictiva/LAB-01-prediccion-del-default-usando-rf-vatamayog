{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0333b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import gzip\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd  # type: ignore\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score, balanced_accuracy_score,\n",
    "    confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27da4984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: c:\\Users\\valen\\Documents\\Maestria\\Analitica Predictiva\\LAB-01-prediccion-del-default-usando-rf-vatamayog\\homework\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e75a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\valen\\\\Documents\\\\Maestria\\\\Analitica Predictiva\\\\LAB-01-prediccion-del-default-usando-rf-vatamayog'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.chdir(\"..\")\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c803806",
   "metadata": {},
   "source": [
    " # Paso 1.\n",
    " Realice la limpieza de los datasets:\n",
    " - Renombre la columna \"default payment next month\" a \"default\".\n",
    " - Remueva la columna \"ID\".\n",
    " - Elimine los registros con informacion no disponible.\n",
    " - Para la columna EDUCATION, valores > 4 indican niveles superiores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d0f745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Paso 1. Cargar y limpiar datos\n",
    "# ============================\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    train_path = 'files/input/train_data.csv.zip'\n",
    "    test_path = 'files/input/test_data.csv.zip'\n",
    "\n",
    "    train_dataset = pd.read_csv(train_path, index_col=False)\n",
    "    test_dataset = pd.read_csv(test_path, index_col=False)\n",
    "    return train_dataset, test_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "384cd0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfbeca05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21000 entries, 0 to 20999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                      Non-Null Count  Dtype\n",
      "---  ------                      --------------  -----\n",
      " 0   ID                          21000 non-null  int64\n",
      " 1   LIMIT_BAL                   21000 non-null  int64\n",
      " 2   SEX                         21000 non-null  int64\n",
      " 3   EDUCATION                   21000 non-null  int64\n",
      " 4   MARRIAGE                    21000 non-null  int64\n",
      " 5   AGE                         21000 non-null  int64\n",
      " 6   PAY_0                       21000 non-null  int64\n",
      " 7   PAY_2                       21000 non-null  int64\n",
      " 8   PAY_3                       21000 non-null  int64\n",
      " 9   PAY_4                       21000 non-null  int64\n",
      " 10  PAY_5                       21000 non-null  int64\n",
      " 11  PAY_6                       21000 non-null  int64\n",
      " 12  BILL_AMT1                   21000 non-null  int64\n",
      " 13  BILL_AMT2                   21000 non-null  int64\n",
      " 14  BILL_AMT3                   21000 non-null  int64\n",
      " 15  BILL_AMT4                   21000 non-null  int64\n",
      " 16  BILL_AMT5                   21000 non-null  int64\n",
      " 17  BILL_AMT6                   21000 non-null  int64\n",
      " 18  PAY_AMT1                    21000 non-null  int64\n",
      " 19  PAY_AMT2                    21000 non-null  int64\n",
      " 20  PAY_AMT3                    21000 non-null  int64\n",
      " 21  PAY_AMT4                    21000 non-null  int64\n",
      " 22  PAY_AMT5                    21000 non-null  int64\n",
      " 23  PAY_AMT6                    21000 non-null  int64\n",
      " 24  default payment next month  21000 non-null  int64\n",
      "dtypes: int64(25)\n",
      "memory usage: 4.0 MB\n"
     ]
    }
   ],
   "source": [
    "train_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecdf82e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9000 entries, 0 to 8999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                      Non-Null Count  Dtype\n",
      "---  ------                      --------------  -----\n",
      " 0   ID                          9000 non-null   int64\n",
      " 1   LIMIT_BAL                   9000 non-null   int64\n",
      " 2   SEX                         9000 non-null   int64\n",
      " 3   EDUCATION                   9000 non-null   int64\n",
      " 4   MARRIAGE                    9000 non-null   int64\n",
      " 5   AGE                         9000 non-null   int64\n",
      " 6   PAY_0                       9000 non-null   int64\n",
      " 7   PAY_2                       9000 non-null   int64\n",
      " 8   PAY_3                       9000 non-null   int64\n",
      " 9   PAY_4                       9000 non-null   int64\n",
      " 10  PAY_5                       9000 non-null   int64\n",
      " 11  PAY_6                       9000 non-null   int64\n",
      " 12  BILL_AMT1                   9000 non-null   int64\n",
      " 13  BILL_AMT2                   9000 non-null   int64\n",
      " 14  BILL_AMT3                   9000 non-null   int64\n",
      " 15  BILL_AMT4                   9000 non-null   int64\n",
      " 16  BILL_AMT5                   9000 non-null   int64\n",
      " 17  BILL_AMT6                   9000 non-null   int64\n",
      " 18  PAY_AMT1                    9000 non-null   int64\n",
      " 19  PAY_AMT2                    9000 non-null   int64\n",
      " 20  PAY_AMT3                    9000 non-null   int64\n",
      " 21  PAY_AMT4                    9000 non-null   int64\n",
      " 22  PAY_AMT5                    9000 non-null   int64\n",
      " 23  PAY_AMT6                    9000 non-null   int64\n",
      " 24  default payment next month  9000 non-null   int64\n",
      "dtypes: int64(25)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "test_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0418aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los tipos de datos son consistentes entre train y test.\n"
     ]
    }
   ],
   "source": [
    "# Verificar si los tipos de datos son los mismos en train y test\n",
    "def validate_data_types(train_df, test_df):\n",
    "    train_dtypes = train_df.dtypes\n",
    "    test_dtypes = test_df.dtypes\n",
    "\n",
    "    # Comparar los tipos de datos\n",
    "    mismatched_columns = [\n",
    "        column for column in train_dtypes.index\n",
    "        if column in test_dtypes.index and train_dtypes[column] != test_dtypes[column]\n",
    "    ]\n",
    "\n",
    "    if mismatched_columns:\n",
    "        print(\"Las siguientes columnas tienen tipos de datos diferentes entre train y test:\")\n",
    "        for column in mismatched_columns:\n",
    "            print(f\"Columna: {column}, Train: {train_dtypes[column]}, Test: {test_dtypes[column]}\")\n",
    "    else:\n",
    "        print(\"Los tipos de datos son consistentes entre train y test.\")\n",
    "\n",
    "# Llamar a la función con los DataFrames de entrenamiento y prueba\n",
    "validate_data_types(train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6262e3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21000, 25), (9000, 25))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape, test_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0a8f86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10748</td>\n",
       "      <td>310000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>84373</td>\n",
       "      <td>57779</td>\n",
       "      <td>14163</td>\n",
       "      <td>8295</td>\n",
       "      <td>6000</td>\n",
       "      <td>4000</td>\n",
       "      <td>3000</td>\n",
       "      <td>1000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12574</td>\n",
       "      <td>10000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1690</td>\n",
       "      <td>1138</td>\n",
       "      <td>930</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2828</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29677</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>45975</td>\n",
       "      <td>1300</td>\n",
       "      <td>43987</td>\n",
       "      <td>0</td>\n",
       "      <td>46257</td>\n",
       "      <td>2200</td>\n",
       "      <td>1300</td>\n",
       "      <td>43987</td>\n",
       "      <td>1386</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8857</td>\n",
       "      <td>80000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>40748</td>\n",
       "      <td>39816</td>\n",
       "      <td>40607</td>\n",
       "      <td>3700</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21099</td>\n",
       "      <td>270000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>22448</td>\n",
       "      <td>15490</td>\n",
       "      <td>17343</td>\n",
       "      <td>0</td>\n",
       "      <td>4000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  \\\n",
       "0  10748     310000    1          3         1   32      0      0      0   \n",
       "1  12574      10000    2          3         1   49     -1     -1     -2   \n",
       "2  29677      50000    1          2         1   28     -1     -1     -1   \n",
       "3   8857      80000    2          3         1   52      2      2      3   \n",
       "4  21099     270000    1          1         2   34      1      2      0   \n",
       "\n",
       "   PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0      0  ...      84373      57779      14163      8295      6000      4000   \n",
       "1     -1  ...       1690       1138        930         0         0      2828   \n",
       "2      0  ...      45975       1300      43987         0     46257      2200   \n",
       "3      3  ...      40748      39816      40607      3700      1600      1600   \n",
       "4      0  ...      22448      15490      17343         0      4000      2000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0      3000      1000      2000                           0  \n",
       "1         0       182         0                           1  \n",
       "2      1300     43987      1386                           0  \n",
       "3         0      1600      1600                           1  \n",
       "4         0      2000      2000                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5885bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13007</td>\n",
       "      <td>13912</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13007</td>\n",
       "      <td>1122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>200000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2513</td>\n",
       "      <td>1828</td>\n",
       "      <td>3731</td>\n",
       "      <td>2306</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "      <td>300</td>\n",
       "      <td>3738</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>250000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>59696</td>\n",
       "      <td>56875</td>\n",
       "      <td>55512</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>3000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28771</td>\n",
       "      <td>29531</td>\n",
       "      <td>30211</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>1100</td>\n",
       "      <td>1200</td>\n",
       "      <td>1300</td>\n",
       "      <td>1100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   2     120000    2          2         2   26     -1      2      0      0   \n",
       "1  10      20000    1          3         2   35     -2     -2     -2     -2   \n",
       "2  11     200000    2          3         2   34      0      0      2      0   \n",
       "3  15     250000    1          1         2   29      0      0      0      0   \n",
       "4  16      50000    2          3         3   23      1      2      0      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...       3272       3455       3261         0      1000      1000   \n",
       "1  ...          0      13007      13912         0         0         0   \n",
       "2  ...       2513       1828       3731      2306        12        50   \n",
       "3  ...      59696      56875      55512      3000      3000      3000   \n",
       "4  ...      28771      29531      30211         0      1500      1100   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0      1000         0      2000                           1  \n",
       "1     13007      1122         0                           0  \n",
       "2       300      3738        66                           0  \n",
       "3      3000      3000      3000                           0  \n",
       "4      1200      1300      1100                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e9ae3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def clean_dataset(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df.rename(columns={\"default payment next month\": \"default\"}, inplace=True)\n",
    "\n",
    "    df.drop(columns=[\"ID\"], inplace=True)\n",
    "\n",
    "    df = df.loc[df[\"MARRIAGE\"] != 0]\n",
    "    df = df.loc[df[\"EDUCATION\"] != 0]\n",
    "\n",
    "    df[\"EDUCATION\"] = df[\"EDUCATION\"].apply(lambda x: 4 if x > 4 else x)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Eliminar duplicados\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Limpiar datasets\n",
    "\n",
    "train_dataset = clean_dataset(train_dataset)\n",
    "test_dataset = clean_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06aad5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en y_train: [0 1]\n",
      "Valores únicos en y_test: [1 0]\n",
      "tipo de datos y_train: int64\n",
      "tipo de datos y_test: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Valores únicos en y_train:\", train_dataset[\"default\"].unique())\n",
    "print(\"Valores únicos en y_test:\", test_dataset[\"default\"].unique())\n",
    "print(\"tipo de datos y_train:\", train_dataset[\"default\"].dtype)\n",
    "print(\"tipo de datos y_test:\", test_dataset[\"default\"].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10a6ef7",
   "metadata": {},
   "source": [
    "# Paso 2.\n",
    "Divida los datasets en x_train, y_train, x_test, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8d38e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_features_target(train_dataset, test_dataset, target_col=\"default\"):\n",
    "    x_train = train_dataset.drop(columns=[target_col])\n",
    "    y_train = train_dataset[target_col].astype(int).values.ravel()\n",
    "    x_test = test_dataset.drop(columns=[target_col])\n",
    "    y_test = test_dataset[target_col].astype(int).values.ravel()\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46681529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaños:\n",
      "x_train: (20934, 23)\n",
      "y_train: (20934,)\n",
      "x_test: (8974, 23)\n",
      "y_test: (8974,)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = split_features_target(train_dataset, test_dataset, \"default\")\n",
    "\n",
    "\n",
    "print(\"Tamaños:\")\n",
    "print(\"x_train:\", x_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"x_test:\", x_test.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0556b9",
   "metadata": {},
   "source": [
    "# Paso 3.\n",
    " Cree un pipeline para el modelo de clasificación. Este pipeline debe\n",
    " contener las siguientes capas:\n",
    " - Transforma las variables categoricas usando el método\n",
    "   one-hot-encoding.\n",
    " - Ajusta un modelo de bosques aleatorios (rando forest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87b2625f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20934 entries, 0 to 20999\n",
      "Data columns (total 23 columns):\n",
      " #   Column     Non-Null Count  Dtype\n",
      "---  ------     --------------  -----\n",
      " 0   LIMIT_BAL  20934 non-null  int64\n",
      " 1   SEX        20934 non-null  int64\n",
      " 2   EDUCATION  20934 non-null  int64\n",
      " 3   MARRIAGE   20934 non-null  int64\n",
      " 4   AGE        20934 non-null  int64\n",
      " 5   PAY_0      20934 non-null  int64\n",
      " 6   PAY_2      20934 non-null  int64\n",
      " 7   PAY_3      20934 non-null  int64\n",
      " 8   PAY_4      20934 non-null  int64\n",
      " 9   PAY_5      20934 non-null  int64\n",
      " 10  PAY_6      20934 non-null  int64\n",
      " 11  BILL_AMT1  20934 non-null  int64\n",
      " 12  BILL_AMT2  20934 non-null  int64\n",
      " 13  BILL_AMT3  20934 non-null  int64\n",
      " 14  BILL_AMT4  20934 non-null  int64\n",
      " 15  BILL_AMT5  20934 non-null  int64\n",
      " 16  BILL_AMT6  20934 non-null  int64\n",
      " 17  PAY_AMT1   20934 non-null  int64\n",
      " 18  PAY_AMT2   20934 non-null  int64\n",
      " 19  PAY_AMT3   20934 non-null  int64\n",
      " 20  PAY_AMT4   20934 non-null  int64\n",
      " 21  PAY_AMT5   20934 non-null  int64\n",
      " 22  PAY_AMT6   20934 non-null  int64\n",
      "dtypes: int64(23)\n",
      "memory usage: 3.8 MB\n"
     ]
    }
   ],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b5fa563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(list_categorical, estimator):\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"), list_categorical)\n",
    "        ],\n",
    "        remainder=\"passthrough\"\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", estimator)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a371bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_categorical = [\"EDUCATION\", \"MARRIAGE\", \"SEX\"]\n",
    "\n",
    "pipeline = make_pipeline(list_categorical, RandomForestClassifier(random_state=42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf59683",
   "metadata": {},
   "source": [
    "#  Paso 4.\n",
    "- Optimice los hiperparametros del pipeline usando validación cruzada.\n",
    "- se 10 splits para la validación cruzada. Use la función de precision\n",
    "- balanceada para medir la precisión del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a19e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_grid_search(pipeline, param_grid, cv, score, x_train, y_train):\n",
    "\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring=score,\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    grid_search.fit(x_train, np.ravel(y_train))\n",
    "\n",
    "    return grid_search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40b4a5a",
   "metadata": {},
   "source": [
    "# Paso 5.\n",
    "- Guarde el modelo (comprimido con gzip) como \"files/models/model.pkl.gz\".\n",
    "- Recuerde que es posible guardar el modelo comprimido usanzo la libreria gzip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e71e07bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_estimator(estimator):\n",
    "    models_path = \"files/models\"\n",
    "    os.makedirs(models_path, exist_ok=True)\n",
    "\n",
    "    with gzip.open(\"files/models/model.pkl.gz\", \"wb\") as file:\n",
    "        pickle.dump(estimator, file)     \n",
    "    print(f\"Modelo guardado en: {'files/models/model.pkl.gz'}\")\n",
    "\n",
    "\n",
    "def load_estimator(output_path):\n",
    "    \"\"\"Cargar modelo comprimido\"\"\"\n",
    "    import gzip, pickle\n",
    "    if not os.path.exists(output_path):\n",
    "        return None\n",
    "    with gzip.open(output_path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a225ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "   \"classifier__n_estimators\": [30, 50, 100],\n",
    "   \"classifier__max_depth\": [None, 10, 20],\n",
    "   \"classifier__min_samples_split\": [5, 10],\n",
    "   \"classifier__min_samples_leaf\": [2, 4],\n",
    "   \"classifier__max_features\": [10, 25]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efce4827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "source": [
    "model = make_grid_search(pipeline, param_grid, cv=10, score=\"balanced_accuracy\", x_train=x_train, y_train=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b30dd291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado en: files/models/model.pkl.gz\n"
     ]
    }
   ],
   "source": [
    "# guardar el modelo entrenado\n",
    "save_estimator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43b618a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"ColumnTransformer(remainder='passthrough',\\n                  transformers=[('onehot',\\n                                 OneHotEncoder(handle_unknown='ignore'),\\n                                 ['EDUCATION', 'MARRIAGE', 'SEX'])])\",\n",
       " 'RandomForestClassifier(random_state=42)']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_components = [str(model.estimator[i]) for i in range(len(model.estimator))]\n",
    "current_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6b2c1a",
   "metadata": {},
   "source": [
    "# Paso 6.\n",
    " Calcule las metricas de precision, precision balanceada, recall,\n",
    " y f1-score para los conjuntos de entrenamiento y prueba.\n",
    " Guardelas en el archivo files/output/metrics.json. Cada fila\n",
    " del archivo es un diccionario con las metricas de un modelo.\n",
    " Este diccionario tiene un campo para indicar si es el conjunto\n",
    " de entrenamiento o prueba. Por ejemplo:\n",
    "\n",
    " {'dataset': 'train', 'precision': 0.8, 'balanced_accuracy': 0.7, 'recall': 0.9, 'f1_score': 0.85}\n",
    " {'dataset': 'test', 'precision': 0.7, 'balanced_accuracy': 0.6, 'recall': 0.8, 'f1_score': 0.75}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f62a57a",
   "metadata": {},
   "source": [
    "# Paso 7.\n",
    " Calcule las matrices de confusion para los conjuntos de entrenamiento y\n",
    " prueba. Guardelas en el archivo files/output/metrics.json. Cada fila\n",
    " del archivo es un diccionario con las metricas de un modelo.\n",
    " de entrenamiento o prueba. Por ejemplo:\n",
    "\n",
    " {'type': 'cm_matrix', 'dataset': 'train', 'true_0': {\"predicted_0\": 15562, \"predicte_1\": 666}, 'true_1': {\"predicted_0\": 3333, \"predicted_1\": 1444}}\n",
    " {'type': 'cm_matrix', 'dataset': 'test', 'true_0': {\"predicted_0\": 15562, \"predicte_1\": 650}, 'true_1': {\"predicted_0\": 2490, \"predicted_1\": 1420}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf73479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(model, x_train, y_train, x_test, y_test):\n",
    "\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "    metrics = [\n",
    "        {\n",
    "            'type': 'metrics',\n",
    "            'dataset': 'train',\n",
    "            'precision': precision_score(y_train, y_train_pred, zero_division=0),\n",
    "            'balanced_accuracy': balanced_accuracy_score(y_train, y_train_pred),\n",
    "            'recall': recall_score(y_train, y_train_pred, zero_division=0),\n",
    "            'f1_score': f1_score(y_train, y_train_pred, zero_division=0)\n",
    "        },\n",
    "        {\n",
    "            'type': 'metrics',\n",
    "            'dataset': 'test',\n",
    "            'precision': precision_score(y_test, y_test_pred, zero_division=0),\n",
    "            'balanced_accuracy': balanced_accuracy_score(y_test, y_test_pred),\n",
    "            'recall': recall_score(y_test, y_test_pred, zero_division=0),\n",
    "            'f1_score': f1_score(y_test, y_test_pred, zero_division=0)\n",
    "        },\n",
    "        {\n",
    "            'type': 'cm_matrix',\n",
    "            'dataset': 'train',\n",
    "            'true_0': {'predicted_0': int(cm_train[0, 0]), 'predicted_1': int(cm_train[0, 1])},\n",
    "            'true_1': {'predicted_0': int(cm_train[1, 0]), 'predicted_1': int(cm_train[1, 1])}\n",
    "        },\n",
    "        {\n",
    "            'type': 'cm_matrix',\n",
    "            'dataset': 'test',\n",
    "            'true_0': {'predicted_0': int(cm_test[0, 0]), 'predicted_1': int(cm_test[0, 1])},\n",
    "            'true_1': {'predicted_0': int(cm_test[1, 0]), 'predicted_1': int(cm_test[1, 1])}\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def save_metrics(metrics):\n",
    "    metrics_path = \"files/output\"\n",
    "    os.makedirs(metrics_path, exist_ok=True)\n",
    "    \n",
    "    with open(\"files/output/metrics.json\", \"w\") as file:\n",
    "        for metric in metrics:\n",
    "            file.write(json.dumps(metric, ensure_ascii=False))\n",
    "            file.write('\\n')\n",
    "\n",
    "    with open(\"files/output/metrics.json\", \"r\") as file:\n",
    "        print(\"Contenido de metrics.json:\")\n",
    "        print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28e577ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenido de metrics.json:\n",
      "{\"type\": \"metrics\", \"dataset\": \"train\", \"precision\": 0.9466415568110483, \"balanced_accuracy\": 0.8139773224105086, \"recall\": 0.6384419983065199, \"f1_score\": 0.7625790139064476}\n",
      "{\"type\": \"metrics\", \"dataset\": \"test\", \"precision\": 0.6578947368421053, \"balanced_accuracy\": 0.6750182003494467, \"recall\": 0.4070378151260504, \"f1_score\": 0.5029201817001947}\n",
      "{\"type\": \"cm_matrix\", \"dataset\": \"train\", \"true_0\": {\"predicted_0\": 16040, \"predicted_1\": 170}, \"true_1\": {\"predicted_0\": 1708, \"predicted_1\": 3016}}\n",
      "{\"type\": \"cm_matrix\", \"dataset\": \"test\", \"true_0\": {\"predicted_0\": 6667, \"predicted_1\": 403}, \"true_1\": {\"predicted_0\": 1129, \"predicted_1\": 775}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = calculate_metrics(model, x_train, y_train, x_test, y_test)\n",
    "\n",
    "save_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b3b53b",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5befbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## primera parte del test\n",
    "\n",
    "MODEL_FILENAME = \"files/models/model.pkl.gz\"\n",
    "MODEL_COMPONENTS = [\n",
    "    \"OneHotEncoder\",\n",
    "    \"RandomForestClassifier\",\n",
    "]\n",
    "SCORES = [\n",
    "    0.785,\n",
    "    0.673,\n",
    "]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#\n",
    "# Internal tests\n",
    "#\n",
    "def _load_model():\n",
    "    \"\"\"Generic test to load a model\"\"\"\n",
    "    assert os.path.exists(MODEL_FILENAME)\n",
    "    with gzip.open(MODEL_FILENAME, \"rb\") as file:\n",
    "        model = pickle.load(file)\n",
    "    assert model is not None\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3f727a",
   "metadata": {},
   "source": [
    "## parte 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fda57138",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = _load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832f51e2",
   "metadata": {},
   "source": [
    "## parte 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29abec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_grading_data():\n",
    "    \"\"\"Load grading data\"\"\"\n",
    "    with open(\"files/grading/x_train.pkl\", \"rb\") as file:\n",
    "        x_train = pickle.load(file)\n",
    "\n",
    "    with open(\"files/grading/y_train.pkl\", \"rb\") as file:\n",
    "        y_train = pickle.load(file)\n",
    "\n",
    "    with open(\"files/grading/x_test.pkl\", \"rb\") as file:\n",
    "        x_test = pickle.load(file)\n",
    "\n",
    "    with open(\"files/grading/y_test.pkl\", \"rb\") as file:\n",
    "        y_test = pickle.load(file)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "x_train, y_train, x_test, y_test = _load_grading_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76530ac9",
   "metadata": {},
   "source": [
    "## parte 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ade3f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_metrics():\n",
    "    assert os.path.exists(\"files/output/metrics.json\")\n",
    "    metrics = []\n",
    "    with open(\"files/output/metrics.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            metrics.append(json.loads(line))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a0e2e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = _load_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e676155e",
   "metadata": {},
   "source": [
    "## parte 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be83ac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_components(model):\n",
    "    \"\"\"Test components\"\"\"\n",
    "    assert \"GridSearchCV\" in str(type(model))\n",
    "    current_components = [str(model.estimator[i]) for i in range(len(model.estimator))]\n",
    "    for component in MODEL_COMPONENTS:\n",
    "        assert any(component in x for x in current_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fec117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_components(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87188be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"ColumnTransformer(remainder='passthrough',\\n                  transformers=[('onehot',\\n                                 OneHotEncoder(handle_unknown='ignore'),\\n                                 ['EDUCATION', 'MARRIAGE', 'SEX'])])\",\n",
       " 'RandomForestClassifier(random_state=42)']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(model.estimator[i]) for i in range(len(model.estimator))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beab5a1f",
   "metadata": {},
   "source": [
    "## parte 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22d3177b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORES = [\n",
    "    0.785,\n",
    "    0.673,\n",
    "]\n",
    "def _test_scores(model, x_train, y_train, x_test, y_test):\n",
    "    \"\"\"Test scores\"\"\"\n",
    "    assert model.score(x_train, y_train) > SCORES[0]\n",
    "    assert model.score(x_test, y_test) > SCORES[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22bfedc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_grading_data():\n",
    "    \"\"\"Load grading data\"\"\"\n",
    "    with open(\"files/grading/x_train.pkl\", \"rb\") as file:\n",
    "        x_train = pickle.load(file)\n",
    "\n",
    "    with open(\"files/grading/y_train.pkl\", \"rb\") as file:\n",
    "        y_train = pickle.load(file)\n",
    "\n",
    "    with open(\"files/grading/x_test.pkl\", \"rb\") as file:\n",
    "        x_test = pickle.load(file)\n",
    "\n",
    "    with open(\"files/grading/y_test.pkl\", \"rb\") as file:\n",
    "        y_test = pickle.load(file)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "x_train, y_train, x_test, y_test = _load_grading_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "208fdad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_model():\n",
    "    with gzip.open(\"files/models/model.pkl.gz\", \"rb\") as file:\n",
    "        model = pickle.load(file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70f12a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = _load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c12679dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_scores(model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8941b370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8140213987712139"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73af0b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6750790623165492"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f0ed598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_train, y_train) > SCORES[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "193c3e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test, y_test) > SCORES[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b7cc1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\valen\\Documents\\Maestria\\Analitica Predictiva\\LAB-01-prediccion-del-default-usando-rf-vatamayog\\.venv\\Scripts\\python.exe\n",
      "C:\\Users\\valen\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\n",
      "C:\\Users\\valen\\AppData\\Local\\Microsoft\\WindowsApps\\python.exe\n"
     ]
    }
   ],
   "source": [
    "!where python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "517e3999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.11.8, pytest-8.4.2, pluggy-1.6.0 -- C:\\Users\\valen\\Documents\\Maestria\\Analitica Predictiva\\LAB-01-prediccion-del-default-usando-rf-vatamayog\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: c:\\Users\\valen\\Documents\\Maestria\\Analitica Predictiva\\LAB-01-prediccion-del-default-usando-rf-vatamayog\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "tests/test_homework.py::test_homework \u001b[32mPASSED\u001b[0m\u001b[32m                             [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 4.02s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest -v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
